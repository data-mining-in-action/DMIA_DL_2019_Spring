{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:18:22.380050Z",
     "start_time": "2019-02-16T14:18:19.243543Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import ssl\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import SVG, Image\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Dense, Conv2D, InputLayer, \n",
    "                          GlobalAveragePooling2D, Activation,\n",
    "                          Dropout, MaxPooling2D, Flatten)\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:18:22.387135Z",
     "start_time": "2019-02-16T14:18:22.382842Z"
    }
   },
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Скачаем данные и посмотрим на них"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем использовать cifar10, подробно прочитать про него можно тут: https://www.cs.toronto.edu/~kriz/cifar.html или тут: https://keras.io/datasets/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:18:22.512586Z",
     "start_time": "2019-02-16T14:18:22.394034Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = ('x_train.npy', 'x_test.npy', 'y_train.npy', 'y_test.npy')\n",
    "if all([os.path.exists('./cifar10/' + filename) for filename in filenames]):\n",
    "    x_train = np.load('cifar10/x_train.npy')\n",
    "    x_test = np.load('cifar10/x_test.npy')\n",
    "    y_train = np.load('cifar10/y_train.npy')\n",
    "    y_test = np.load('cifar10/y_test.npy')\n",
    "else:\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    \n",
    "    str_2_var = {'x_train': x_train,\n",
    "             'x_test': x_test,\n",
    "             'y_train': y_train,\n",
    "             'y_test': y_test}\n",
    "    \n",
    "    if not os.path.exists('cifar10/'):\n",
    "        os.mkdir('cifar_10/')\n",
    "\n",
    "    for var_str, var_name in str_2_var.items():\n",
    "        np.save('cifar10_' + var_str + '.npy', var_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:18:22.520310Z",
     "start_time": "2019-02-16T14:18:22.516314Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer',\n",
    "               5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:18:23.109464Z",
     "start_time": "2019-02-16T14:18:22.524417Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,3))\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    ax.set_title(class_names[i])\n",
    "    idx = np.where(y_train[:]==i)[0][0]\n",
    "    image = x_train[idx]\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классическое компьютерное зрение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T19:57:33.511229Z",
     "start_time": "2018-12-02T19:57:12.952794Z"
    }
   },
   "source": [
    "### Histogram of Oriented Gradients (HoG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:18:23.129297Z",
     "start_time": "2019-02-16T14:18:23.113200Z"
    }
   },
   "outputs": [],
   "source": [
    "Image('pics/hog.png', width=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of Oriented Gradients - способ извлечения признаков из изображений. Главная идея - найти направления граней на изображении по их интенсивности, а затем использовать их частоту (преобразованную каким-либо хитрым способом) как признаки изображения. Подробнее про HoG можно почитать тут: https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:19:01.976620Z",
     "start_time": "2019-02-16T14:18:23.132643Z"
    }
   },
   "outputs": [],
   "source": [
    "print('HoG features for train set')\n",
    "x_train_hog = []\n",
    "for i in tqdm.tqdm_notebook(range(len(x_train))):\n",
    "    img_hog = hog(image=x_train[i],\n",
    "                  pixels_per_cell=(8, 8),\n",
    "                  block_norm='L2-Hys')\n",
    "    x_train_hog.append(img_hog)\n",
    "x_train_hog = np.array(x_train_hog)\n",
    "    \n",
    "print('HoG features for test set')\n",
    "x_test_hog = []\n",
    "for i in tqdm.tqdm_notebook(range(len(x_test))):\n",
    "    img_hog = hog(image=x_test[i],\n",
    "                  pixels_per_cell=(8, 8),\n",
    "                  block_norm='L2-Hys')\n",
    "    x_test_hog.append(img_hog)\n",
    "x_test_hog = np.array(x_test_hog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим логистическуб регрессию на HoG признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:19:01.984512Z",
     "start_time": "2019-02-16T14:19:01.979862Z"
    }
   },
   "outputs": [],
   "source": [
    "model_logreg_hog = LogisticRegression(solver='saga', multi_class='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:19:22.154325Z",
     "start_time": "2019-02-16T14:19:01.987854Z"
    }
   },
   "outputs": [],
   "source": [
    "model_logreg_hog.fit(x_train_hog, y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:19:22.270249Z",
     "start_time": "2019-02-16T14:19:22.157394Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_logreg_hog_train = model_logreg_hog.predict(x_train_hog)\n",
    "preds_logreg_hog_test = model_logreg_hog.predict(x_test_hog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценим качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:19:22.286633Z",
     "start_time": "2019-02-16T14:19:22.272625Z"
    }
   },
   "outputs": [],
   "source": [
    "print('HOG + Logistic regression train accuracy')\n",
    "print(accuracy_score(y_train.flatten(), preds_logreg_hog_train))\n",
    "print('')\n",
    "print('HOG + Logistic regression test accuracy')\n",
    "print(accuracy_score(y_test.flatten(), preds_logreg_hog_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глубокое обучение в компьютерном зрении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код частично взят из репозитория keras: https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определим модель и обучим ее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель будет простой, 2 блока последовательных сверток и пулингов, после которых простой перцептрон предсказывает класс изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:19:22.300048Z",
     "start_time": "2019-02-16T14:19:22.290554Z"
    }
   },
   "outputs": [],
   "source": [
    "Image('pics/simple_convolution.jpg', width=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:19:22.315857Z",
     "start_time": "2019-02-16T14:19:22.304363Z"
    }
   },
   "outputs": [],
   "source": [
    "Image('pics/pooling.png', width=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:19:22.506941Z",
     "start_time": "2019-02-16T14:19:22.319972Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dl = Sequential()\n",
    "\n",
    "model_dl.add(Conv2D(filters=32,\n",
    "                    kernel_size=(3, 3),\n",
    "                    padding='same',\n",
    "                    input_shape=x_train.shape[1:]))\n",
    "model_dl.add(Activation('relu'))\n",
    "model_dl.add(Conv2D(filters=32,\n",
    "                    kernel_size=(3, 3)))\n",
    "model_dl.add(Activation('relu'))\n",
    "model_dl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_dl.add(Dropout(0.25))\n",
    "\n",
    "model_dl.add(Conv2D(filters=64,\n",
    "                    kernel_size=(3, 3),\n",
    "                    padding='same'))\n",
    "model_dl.add(Activation('relu'))\n",
    "model_dl.add(Conv2D(filters=64,\n",
    "                    kernel_size=(3, 3)))\n",
    "model_dl.add(Activation('relu'))\n",
    "model_dl.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_dl.add(Dropout(0.25))\n",
    "\n",
    "model_dl.add(Flatten())\n",
    "model_dl.add(Dense(units=128))\n",
    "model_dl.add(Activation('relu'))\n",
    "model_dl.add(Dropout(0.5))\n",
    "model_dl.add(Dense(units=10))\n",
    "model_dl.add(Activation('softmax', name='out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:19:22.522693Z",
     "start_time": "2019-02-16T14:19:22.509148Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_dl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:19:22.621529Z",
     "start_time": "2019-02-16T14:19:22.526370Z"
    }
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model_dl).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:19:22.715025Z",
     "start_time": "2019-02-16T14:19:22.636995Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001)\n",
    "\n",
    "model_dl.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics={'out': 'acc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:20:26.687137Z",
     "start_time": "2019-02-16T14:19:22.724402Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model_dl.fit(\n",
    "    x=x_train/255.,\n",
    "    y=to_categorical(y_train, num_classes=10),\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test/255., to_categorical(y_test, num_classes=10)),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:20:26.705140Z",
     "start_time": "2019-02-16T14:18:19.296Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_dl_train = model_dl.predict(x_train/255., verbose=1, batch_size=64)\n",
    "preds_dl_test = model_dl.predict(x_test/255., verbose=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценим качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:20:26.708387Z",
     "start_time": "2019-02-16T14:18:19.300Z"
    }
   },
   "outputs": [],
   "source": [
    "print('CNN train accuracy')\n",
    "print(accuracy_score(y_train.flatten(), np.argmax(preds_dl_train, axis=1)))\n",
    "print('')\n",
    "print('CNN test accuracy')\n",
    "print(accuracy_score(y_test.flatten(), np.argmax(preds_dl_test, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на динамику обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T14:20:26.712098Z",
     "start_time": "2019-02-16T14:18:19.303Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,7.5))\n",
    "\n",
    "epochs = range(1, len(history.history['acc']) + 1)\n",
    "\n",
    "plt.plot(epochs, history.history['acc'], 'r', label='Training loss')\n",
    "plt.plot(epochs, history.history['val_acc'], 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
